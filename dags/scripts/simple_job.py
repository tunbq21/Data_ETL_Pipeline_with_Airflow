from pyspark.sql import SparkSession

# Táº¡o SparkSession
spark = SparkSession.builder.appName("SimpleSparkJob").getOrCreate()

# Äá»c file CSV máº«u
data = spark.read.csv("/opt/airflow/dags/scripts/data.csv", header=True)

# Äáº¿m sá»‘ dÃ²ng
count = data.count()
print(f"ğŸ“Š Sá»‘ dÃ²ng trong file CSV lÃ : {count}")

spark.stop()
